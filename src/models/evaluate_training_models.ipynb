{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Realice una clasificación de los mismos y evalúe su desempeño utilizando la métrica de evaluación AMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../utils\")\n",
    "\n",
    "from HiggsBosonUtils import AMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MODELS_PATH = \"./trained-models\"\n",
    "INPUT_DATA_PATH = \"../../data/output\"\n",
    "data_training = pd.read_csv('../../data/input/training.csv')\n",
    "X_train = np.loadtxt(f\"{INPUT_DATA_PATH}/X_train.txt\")\n",
    "y_train = np.loadtxt(f\"{INPUT_DATA_PATH}/y_train.txt\")\n",
    "\n",
    "weights = np.array(data_training['Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\miniconda3\\envs\\TAA\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = pickle.load(open(f\"{INPUT_MODELS_PATH}/rf.sav\", 'rb'))\n",
    "dt_clf = pickle.load(open(f\"{INPUT_MODELS_PATH}/dt.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (Desicion Tree) =  67.71112289505676\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt = dt_clf.predict(X_train)\n",
    "\n",
    "s = data_training.loc[(y_pred_dt == 1) & (y_train == 1)].Weight.sum()\n",
    "b = data_training.loc[(y_pred_dt == 1) & (y_train == 0)].Weight.sum()\n",
    "\n",
    "print('AMS train (Desicion Tree) = ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (Random Forest) =  67.70627582003308\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_clf.predict(X_train)\n",
    "\n",
    "s = data_training.loc[(y_pred_rf == 1) & (y_train == 1)].Weight.sum()\n",
    "b = data_training.loc[(y_pred_rf == 1) & (y_train == 0)].Weight.sum()\n",
    "\n",
    "print('AMS train (Random Forest) = ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (Caso Ideal) =  67.71112289505676\n"
     ]
    }
   ],
   "source": [
    "s = data_training.loc[ (y_train == 1)].Weight.sum()\n",
    "b = 0\n",
    "\n",
    "print('AMS train (Caso Ideal) = ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (todos se predicen como Signal) =  1.0790735173438217\n"
     ]
    }
   ],
   "source": [
    "s = data_training.loc[y_train == 1].Weight.sum()\n",
    "b = data_training.loc[y_train == 0].Weight.sum()\n",
    "\n",
    "print('AMS train (todos se predicen como Signal) = ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (todos se predicen como Background) =  0.0\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "b = 0\n",
    "\n",
    "print('AMS train (todos se predicen como Background) = ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peor caso AMS = 0, pq s=0 (train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Parte 3 -  Un primer pipeline\n",
    "\n",
    " - Probar clasificar los datos del proyecto con los distintos métodos vistos en este taller (Árboles de Decisión, Random Forest, XGBoost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = pickle.load(open(f\"{INPUT_MODELS_PATH}/dt.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (desicion tree)=  67.71112289505676\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt = dt_clf.predict(X_train)\n",
    "\n",
    "s = data_training.loc[(y_pred_dt == 1) & (y_train == 1)].Weight.sum()\n",
    "b = data_training.loc[(y_pred_dt == 1) & (y_train == 0)].Weight.sum()\n",
    "\n",
    "print('AMS train (desicion tree)= ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = pickle.load(open(f\"{INPUT_MODELS_PATH}/xgb.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS train (XGBoost) =  3.0588212616821546\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb_clf.predict(X_train)\n",
    "\n",
    "s = data_training.loc[(y_pred_xgb == 1) & (y_train == 1)].Weight.sum()\n",
    "b = data_training.loc[(y_pred_xgb == 1) & (y_train == 0)].Weight.sum()\n",
    "\n",
    "print('AMS train (XGBoost) = ', AMS(s, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Parte 4 -  Un primer pipeline\n",
    "Descargue la implementación de la métrica de la página del [curso](https://eva.fing.edu.uy/mod/resource/view.php?id=135850). Modifique el nombre del archivo descargado a *HiggsBosonUtils.py* y guarde dicho archivo en una carpeta *tools* en el mismo directorio donde está el presente Notebook. En estas condiciones, puede importar la función *AMS* contenida dentro de *HiggsBosonUtils.py* de la siguiente forma:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- será necesario también fijar un punto de operación que maximice el desempeño de la métrica, en este caso, el *AMS*. En función de ello, resulta pertinente observar que valores resultan razonables para dicha métrica.\n",
    "\n",
    "#### Objetivos:\n",
    "\n",
    " - Levantar el conjunto de datos del proyecto. \n",
    " - Obtener el desempeño de *AMS* obtenido si el modelo clasifica todos los eventos como *background*.\n",
    " - Obtener el desempeño de *AMS* obtenido si el modelo clasifica todos los eventos como *signal*.\n",
    " - Obtener el desempeño de *AMS* obtenido si el modelo clasifica perfectamente todos los eventos.\n",
    " - Observe los Leaderboard de Kaggle y en base a los resultados obtenidos anteriormente que discuta que valores le resultan razonables de *AMS*.\n",
    " - Con los datos del proyecto genere dos conjuntos uno de Entrenamiento y otro de Validación. Luego, entrene el modelo y evalúe el desempeño en el conjunto de Validación. Observe como varía el AMS al modificar el umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from HiggsBosonUtils import AMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_s_and_b_values(data):\n",
    "    data['Label'] = data['Label'].map({'b': 0, 's': 1})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691.9886077125524 410999.8473218613\n"
     ]
    }
   ],
   "source": [
    "data = map_s_and_b_values(data_training)\n",
    "weights_signal_bs = data.loc[(data['Label'] == 1)].Weight.sum()\n",
    "weights_bg_bs = data.loc[(data['Label'] == 0)].Weight.sum()\n",
    "print(weights_signal_bs, weights_bg_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.797206612600598]\n",
      "[2.797206612600598, 2.8000981967871534]\n",
      "[2.797206612600598, 2.8000981967871534, 2.8073202951254013]\n",
      "[2.856655981580789]\n",
      "[2.856655981580789, 2.845690497203011]\n",
      "[2.856655981580789, 2.845690497203011, 2.846780621109384]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "grid_rf = {'n_estimators': [50, 200]}\n",
    "\n",
    "best_score = 0\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "\n",
    "for g in ParameterGrid(grid_rf):\n",
    "    rf.set_params(**g)\n",
    "    score = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_skf, X_test_skf = X_train[train_index], X_train[test_index]\n",
    "        y_train_skf, y_test_skf = y_train[train_index], y_train[test_index]\n",
    "        weights_train = weights[train_index]\n",
    "        weights_test = weights[test_index]\n",
    "    \n",
    "        # ajuste de pesos\n",
    "        weight_signal_as = weights_train[y_train_skf == 1].sum()\n",
    "        weight_bg_as = weights_train[y_train_skf == 0].sum()\n",
    "        weights_train[y_train_skf == 1] *= (weights_signal_bs/weight_signal_as)\n",
    "        weights_train[y_train_skf == 0] *= (weights_bg_bs/weight_bg_as)\n",
    "\n",
    "        weight_signal_as = weights_test[y_test_skf == 1].sum()\n",
    "        weight_bg_as = weights_test[y_test_skf == 0].sum()\n",
    "        weights_test[y_test_skf == 1] *= (weights_signal_bs/weight_signal_as)\n",
    "        weights_test[y_test_skf == 0] *= (weights_bg_bs/weight_bg_as)\n",
    "\n",
    "        rf.fit(X_train_skf, y_train_skf)\n",
    "        # score con AMS\n",
    "        y_pred_skf = rf.predict(X_test_skf)\n",
    "        s = weights_test[(y_pred_skf==1) & (y_test_skf==1)].sum()\n",
    "        b = weights_test[(y_pred_skf==1) & (y_test_skf==0)].sum()\n",
    "        score.append(AMS(s, b))\n",
    "        print(score)\n",
    "    mean_score = np.mean(score)\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_grid = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.849709033297728\n",
      "{'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(best_score)\n",
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "664f1adae8684a08f3cc182a06030f4736147a48fdadc49b8444ddeeb7bd1d0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('fing-FUAA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
